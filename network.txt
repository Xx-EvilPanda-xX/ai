[1, 30, 1]

Layer 2:
    Node 1:
        Bias:
            0.9409237605038743
        Incoming weights:
            0.9158082973651861
    Node 2:
        Bias:
            -3.047077799049029
        Incoming weights:
            0.49772852836740694
    Node 3:
        Bias:
            1.1998916340810188
        Incoming weights:
            0.35480984248891473
    Node 4:
        Bias:
            0.42082007051885034
        Incoming weights:
            -0.013460997610499646
    Node 5:
        Bias:
            0.39674361306460004
        Incoming weights:
            0.8103717548791857
    Node 6:
        Bias:
            3.6987078050532944
        Incoming weights:
            -0.5557903448068906
    Node 7:
        Bias:
            2.0752871865543945
        Incoming weights:
            -0.3972140380544741
    Node 8:
        Bias:
            1.1785785120813346
        Incoming weights:
            0.32890206897031177
    Node 9:
        Bias:
            1.2883000242384444
        Incoming weights:
            0.33777662092142113
    Node 10:
        Bias:
            0.07135841128830364
        Incoming weights:
            0.6369072074335346
    Node 11:
        Bias:
            -1.8710699978568603
        Incoming weights:
            -0.3904984005435831
    Node 12:
        Bias:
            -2.129049439580645
        Incoming weights:
            0.4007566060963849
    Node 13:
        Bias:
            -2.584013082649264
        Incoming weights:
            -0.4607295254425249
    Node 14:
        Bias:
            0.3341263587326812
        Incoming weights:
            0.3220336291416303
    Node 15:
        Bias:
            0.5575723076229662
        Incoming weights:
            -0.002142906256636129
    Node 16:
        Bias:
            0.0644065216848484
        Incoming weights:
            0.3098446281126627
    Node 17:
        Bias:
            0.8178980058598173
        Incoming weights:
            0.31326339557725535
    Node 18:
        Bias:
            1.348460729725672
        Incoming weights:
            -0.33127610227852056
    Node 19:
        Bias:
            0.31682619369092757
        Incoming weights:
            0.0009771058357503995
    Node 20:
        Bias:
            0.3911058669286014
        Incoming weights:
            -0.008413706918013093
    Node 21:
        Bias:
            0.3226456883962261
        Incoming weights:
            -0.04273421029546647
    Node 22:
        Bias:
            1.4067324070468783
        Incoming weights:
            -0.2481966022140887
    Node 23:
        Bias:
            -3.8205772191873484
        Incoming weights:
            0.5070990397827171
    Node 24:
        Bias:
            2.4099094833544097
        Incoming weights:
            0.3589286607312721
    Node 25:
        Bias:
            -0.06982881461598016
        Incoming weights:
            -0.31975257890705555
    Node 26:
        Bias:
            0.6843232080000502
        Incoming weights:
            0.8858485400883278
    Node 27:
        Bias:
            -2.97201057211829
        Incoming weights:
            -0.4082113243826454
    Node 28:
        Bias:
            0.11654043328008633
        Incoming weights:
            -0.1652923006256339
    Node 29:
        Bias:
            2.2934925147941834
        Incoming weights:
            -0.26751776410979156
    Node 30:
        Bias:
            -1.4298675903021014
        Incoming weights:
            -0.20962503493259926

Layer 3:
    Node 1:
        Bias:
            1.5471287028229985
        Incoming weights:
            0.9462687103849271
            2.008380256171509
            -0.7402238106205272
            1.8880322608206939
            0.10032404585609069
            -2.2118127151462055
            -1.0310453432721367
            -0.8316799889166812
            -0.9417561116900377
            0.06732135019944568
            2.0258380926569233
            1.8640847728705696
            2.4353508862628126
            -0.5784582225293099
            1.501913439994963
            1.4115349740415088
            -0.7263771296356418
            -0.5805707252950562
            0.8287022720724364
            2.617359379554729
            1.789856095457602
            -0.8067707850774313
            3.3310767604209
            -2.071079519544084
            0.5349966072430824
            0.3881316570629999
            2.9232474425187824
            0.611877058718806
            -1.7283764678720241
            1.8053019813223714

