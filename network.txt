[1, 10, 10, 10, 1]

Layer 2:
    Node 1:
        Bias:
            0.3557891666354579
        Incoming weights:
            -0.14239636530338806
    Node 2:
        Bias:
            -0.8161266070628862
        Incoming weights:
            0.17012649253609285
    Node 3:
        Bias:
            0.5519452556502562
        Incoming weights:
            1.1668510571628312
    Node 4:
        Bias:
            -0.00021597773360835075
        Incoming weights:
            -0.9169672595511006
    Node 5:
        Bias:
            0.41449275963780774
        Incoming weights:
            -1.1359797774795033
    Node 6:
        Bias:
            -0.35167930894912824
        Incoming weights:
            -0.14048236857802035
    Node 7:
        Bias:
            -0.45527160486170315
        Incoming weights:
            -0.962136408722404
    Node 8:
        Bias:
            0.3647668355203713
        Incoming weights:
            0.8080806525230204
    Node 9:
        Bias:
            -0.4541849477278582
        Incoming weights:
            -0.9162991298028416
    Node 10:
        Bias:
            -0.7851579739494783
        Incoming weights:
            -1.3540136211234453

Layer 3:
    Node 1:
        Bias:
            -0.025882745813347388
        Incoming weights:
            0.8976522132975759
            -0.39691869041121275
            -0.35382714142662774
            -0.2529287056154247
            0.21313635042900483
            -0.7903599862580166
            0.9332582684810848
            -0.00362968651225899
            0.6088910636006755
            -0.8099696764295935
    Node 2:
        Bias:
            -0.17117362696589983
        Incoming weights:
            -1.509487749519853
            0.4059580469799974
            -0.9401313575432712
            0.6429049349048753
            -0.7182271111790525
            -0.6030008334006871
            0.8552341533584581
            0.8206816034319923
            0.6797373332806456
            1.005646635662147
    Node 3:
        Bias:
            -0.514881337259203
        Incoming weights:
            -0.6461538423449839
            -0.6985284841590492
            -0.5947674981258554
            0.9246372526277193
            -0.33751606136980483
            0.34000152992643934
            -0.2462835596075669
            0.09367322412321002
            -0.04457007641815742
            0.5455283038918182
    Node 4:
        Bias:
            0.5146306835802684
        Incoming weights:
            0.5449893050419327
            0.5184849692792973
            -0.6838616893018608
            -0.7694568093533944
            0.5468892495317114
            0.16050471629894666
            -0.9235014440884161
            0.3640807199878317
            0.6153138488365644
            0.6690641017101819
    Node 5:
        Bias:
            -0.16321288164589795
        Incoming weights:
            0.7001537363362794
            -0.558278009421148
            -0.19982518950296743
            0.18622354116908157
            0.11903372874295726
            0.2718398013213326
            0.24293569148482913
            0.3158973404724134
            0.41515337641961075
            0.32586410284036016
    Node 6:
        Bias:
            -0.1131435148171533
        Incoming weights:
            -0.7753330077066504
            0.996949651742866
            -0.7083276733181689
            -0.4108351618547308
            0.9039380405389077
            -1.2777069032388089
            0.4132378388234958
            0.6619059380858836
            -0.20878151542604184
            0.8778804095922825
    Node 7:
        Bias:
            -0.744978492095583
        Incoming weights:
            -0.24995716803235685
            0.49395336901894166
            -0.43910964637486904
            0.6629889687805387
            0.505156458449458
            -0.7140257799198092
            -0.8366106596168267
            -0.7752647538941853
            0.9850557243539568
            1.1062067396668949
    Node 8:
        Bias:
            -0.3396707705017145
        Incoming weights:
            -0.05692379708109046
            0.8422523739753401
            0.21053308920591096
            -0.12979022290817005
            0.15958959485102628
            0.6509243531009533
            -1.1093183533003679
            0.9367382655442316
            0.4212005124505095
            0.5184621658297199
    Node 9:
        Bias:
            1.0116133287771616
        Incoming weights:
            -0.5710674461512829
            0.895679160824838
            0.21222967451015035
            -0.33158046410469416
            -0.7915884909837685
            1.215236766104789
            -0.9796921175667972
            0.4820357193349225
            -0.3708308968606496
            -0.9084269847301535
    Node 10:
        Bias:
            -0.6873127071900216
        Incoming weights:
            -0.4511347988873535
            1.0131129290972472
            1.080075588729429
            -0.24785256196483263
            -0.3398413048825631
            -0.8096123055066695
            0.3421093341822134
            0.8226807997969356
            -0.6047070544322732
            -0.40545577161706603

Layer 4:
    Node 1:
        Bias:
            0.0692682897089582
        Incoming weights:
            -0.3119157428718281
            0.29732912830897856
            -0.012685353512225798
            0.5053656682591512
            -0.6009757168119474
            1.1704453427312902
            -0.3746843423365543
            -0.43861805424009914
            -0.8065006163191488
            0.4127013525155494
    Node 2:
        Bias:
            -0.9822537312308458
        Incoming weights:
            0.75388666669996
            -0.10960576705940563
            -0.7260022971552601
            -0.6905743897687213
            -1.0343302341411966
            -0.16398995443576936
            0.017102444656463274
            0.37799782487858535
            -0.021903796892311495
            0.32280441215306
    Node 3:
        Bias:
            -0.38275413736141556
        Incoming weights:
            0.20437997769662283
            -0.29120007314244095
            -1.0269943322182924
            -0.1236530694144392
            0.7318345362025321
            -1.170190966870861
            -0.5011967827012339
            0.9300681255238517
            1.2598379803832302
            -0.2938878347908129
    Node 4:
        Bias:
            0.3194453343612453
        Incoming weights:
            -0.16617932784540623
            0.9428753100777987
            -0.08151690064071508
            -0.783359873728492
            -0.9215342593235024
            -0.0060860978724757075
            0.6269990477840441
            0.5144360567504753
            0.6011733940596631
            0.11100978689029793
    Node 5:
        Bias:
            1.0006288195162625
        Incoming weights:
            -0.7171280674436551
            0.11210999549558076
            -0.9156123232654718
            -0.317869767246534
            0.7328808605649139
            0.8781680754559169
            -0.38755997892501115
            0.22178022635747371
            -0.27350943640603936
            0.8805145489584725
    Node 6:
        Bias:
            0.9670669946978663
        Incoming weights:
            0.09972968636933796
            0.7766269258601334
            0.669580837763219
            0.8170701428941098
            0.49472570294177054
            0.7544438487002714
            0.7611582651430359
            0.11944495147762405
            0.8250351715969902
            0.6163114884944301
    Node 7:
        Bias:
            -0.43941033541030267
        Incoming weights:
            0.11112724007679924
            1.1798197688806922
            0.2418914545196661
            0.43051331287537437
            0.045346862142679
            0.2754481965394603
            1.1306350037788062
            -0.4630929806308603
            -0.6511513202307875
            -1.1116088410040041
    Node 8:
        Bias:
            -0.7354494485961373
        Incoming weights:
            0.7020638607114852
            0.3978463697043255
            -0.7367494605188507
            -0.0015061527365067397
            0.18901489430732246
            0.11225013923399024
            0.23294614567156086
            0.43354628460292377
            -0.7169142680022458
            0.23057707904521688
    Node 9:
        Bias:
            0.44774147360854905
        Incoming weights:
            -0.4146284690898543
            0.6428939972220709
            -0.4907402461442538
            0.012346660122032529
            0.03667506057028575
            0.5185708194678442
            0.9139328045510616
            -0.9603377692620155
            -0.29138915525896786
            -1.0733525078831678
    Node 10:
        Bias:
            0.12229145006654507
        Incoming weights:
            0.2641177937324481
            -0.9103904027456797
            0.2224328806899343
            0.4730333103735397
            -0.17761472137445528
            -0.7958446484426569
            -1.0215359997683071
            -0.4701501076727367
            1.22414123419241
            -0.18866284534115166

Layer 5:
    Node 1:
        Bias:
            -0.17885720734830385
        Incoming weights:
            -1.030250325221215
            -0.6731401165872398
            1.8304538276747786
            -0.7670618360009108
            0.28848863116623236
            0.7728732408362695
            -1.6919317220693395
            -0.29293435499980125
            -1.3867608228816335
            1.6567242307892847

