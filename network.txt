[1, 10, 10, 10, 1]

Layer 2:
    Node 1:
        Bias:
            0.26528189442233246
        Incoming weights:
            -0.6132715761122137
    Node 2:
        Bias:
            1.8972192988399463
        Incoming weights:
            1.1107945656522626
    Node 3:
        Bias:
            -1.515717226512422
        Incoming weights:
            -0.2026830834148222
    Node 4:
        Bias:
            0.7636544159259918
        Incoming weights:
            0.5803760398783372
    Node 5:
        Bias:
            1.9892284010896373
        Incoming weights:
            -0.5365228569724678
    Node 6:
        Bias:
            0.5428614810066353
        Incoming weights:
            -0.40188877897663366
    Node 7:
        Bias:
            2.105999730077993
        Incoming weights:
            0.10498778730798218
    Node 8:
        Bias:
            0.8188492402810365
        Incoming weights:
            -0.5694098924710301
    Node 9:
        Bias:
            -1.3109728735533093
        Incoming weights:
            0.7304536165731168
    Node 10:
        Bias:
            -1.369457725909434
        Incoming weights:
            0.08364402202497456

Layer 3:
    Node 1:
        Bias:
            -1.8810828047052799
        Incoming weights:
            0.3351977724498664
            0.8073320919220653
            0.6332196003849433
            2.0924298509573003
            -0.9766675006006489
            1.980539371881175
            -1.3303926009663913
            3.737602529794866
            -2.525942396646753
            0.3672513776695408
    Node 2:
        Bias:
            0.6389227711880423
        Incoming weights:
            -1.305139040511527
            0.360250782863556
            0.3422679074102249
            0.01819374238857757
            0.9192533958799554
            0.8950881591827824
            3.039161990089807
            -0.09985414856836344
            3.9891979520796497
            0.5814573504604105
    Node 3:
        Bias:
            3.339164047267799
        Incoming weights:
            1.4890904380144196
            1.7045708766258634
            0.4905184355688276
            -0.7280927542467787
            1.1507377596580801
            -0.29677927130477477
            2.5619690244015643
            0.7354807222334904
            0.006892504051545508
            0.6200595407480288
    Node 4:
        Bias:
            -3.5389550146918864
        Incoming weights:
            -1.3600765858180324
            -1.2923415377482776
            -1.996407877288757
            -3.0828051716499885
            2.7108074582057093
            -0.7824141800639609
            0.4077642081418902
            -0.38282289948268966
            -0.27399344679555615
            0.14362390801630726
    Node 5:
        Bias:
            0.3951245481063392
        Incoming weights:
            -0.3003962261604811
            -1.5826438006456922
            -0.36237403250565764
            0.5366941999570638
            2.5570734432485187
            0.10402021840744623
            0.6378166459863311
            -2.00044777719904
            2.7364810964147934
            1.4124277652374124
    Node 6:
        Bias:
            3.2913747775876754
        Incoming weights:
            1.0078656769124332
            -0.5101219690294094
            -0.6064076737662256
            -0.5027623353229697
            -0.6820598743255157
            1.6794014281189582
            1.9693696462536456
            -0.4127468278300325
            0.9229086406701422
            -4.327927906379644
    Node 7:
        Bias:
            -3.5878356248381054
        Incoming weights:
            -0.026927890409360986
            3.317668538692582
            1.0941679714359542
            1.0211940515785973
            4.240747644786947
            1.1593810725758578
            0.6825886435167591
            1.300540710363974
            -0.5176446377271049
            -0.6138019322092847
    Node 8:
        Bias:
            0.8263321446558415
        Incoming weights:
            1.1271340136482728
            2.444174390814228
            1.6818974833691942
            -0.9838122119075001
            -0.7784444089260547
            2.594703051858702
            0.7412374017697909
            4.499845837263536
            -1.5579345951730441
            -0.05716511581595971
    Node 9:
        Bias:
            -0.12381279853020567
        Incoming weights:
            -0.7722561310864214
            -1.8081990701366613
            1.982709423098706
            0.09873161352609344
            -0.4512611082825226
            1.6870827666923727
            -0.023243268675475284
            -1.369465350961936
            -1.9070093159114532
            0.44082074472009136
    Node 10:
        Bias:
            1.6946001434891833
        Incoming weights:
            0.26043561993100306
            1.6365324362816507
            -0.4265269109187483
            0.9033931480709404
            0.847048195717307
            -3.270569738915107
            1.1393984452877426
            0.30655188232682784
            0.4536406037632413
            2.5061338829567674

Layer 4:
    Node 1:
        Bias:
            -0.529353417562787
        Incoming weights:
            2.094887557650564
            2.0891277794596084
            -1.056674211694183
            -0.5205178251940222
            1.752701538394923
            -0.6919580554932806
            0.7491042633399901
            1.8929097631425893
            1.7429924525437739
            4.203167875161698
    Node 2:
        Bias:
            1.3492704449382964
        Incoming weights:
            2.8175268631350683
            1.4560388802567321
            1.325634806558129
            0.5607928527741938
            0.05725708200449785
            2.6922972615326137
            1.8030678418976014
            1.076992645957951
            0.04444914734862847
            1.2918886478649276
    Node 3:
        Bias:
            0.18121236346145297
        Incoming weights:
            -2.6620281223793576
            -2.4598816001014527
            1.664926456194709
            -0.5950471360190785
            -3.28613897447006
            -0.30230102365322464
            -0.23907491360930477
            -0.3889174051272436
            -3.910715969000475
            -2.079691421499962
    Node 4:
        Bias:
            -1.3983400851240408
        Incoming weights:
            -2.8175810092738556
            -1.4978302957576808
            -2.5473148127484984
            -0.2955527632453739
            0.010426914134721464
            -0.7188971447327617
            0.62563375148899
            -1.3158898020965184
            -1.3926241240284787
            0.9228460631945415
    Node 5:
        Bias:
            -0.10799076981962362
        Incoming weights:
            -1.2653382582605763
            -2.112595516313105
            -1.6492560865165555
            0.11032259101165955
            -0.5009334799803242
            -4.442396987318035
            -1.1020372910225857
            0.3705312116652997
            2.812899585383428
            -0.5638419002556636
    Node 6:
        Bias:
            -2.9783172388999626
        Incoming weights:
            -0.2993451085283507
            -1.3745292995132412
            -2.027424239738011
            1.475857190654697
            0.3982928565637827
            0.9259379871351066
            -1.0919908690822746
            -0.8902388189765529
            -1.7159250980766536
            -0.878176153150965
    Node 7:
        Bias:
            -0.7399892850722366
        Incoming weights:
            -1.728118503408219
            -1.5867601530695574
            -0.9078117422769892
            0.5710633644167947
            -5.4274079599679865
            -1.1471922687326923
            -0.6788081691964845
            -4.761439219570851
            0.2587182643234301
            -0.14918514382206394
    Node 8:
        Bias:
            0.2474457539233002
        Incoming weights:
            -3.1469622155887342
            -2.1841745495866696
            0.3433078678291976
            2.197792432215959
            3.4726056567403525
            -1.6537480637718838
            -1.8530472012534571
            -6.352158144045478
            3.9675503766645406
            -3.2235872865284843
    Node 9:
        Bias:
            -3.9355788663563254
        Incoming weights:
            -0.086948969126281
            2.1204632684230917
            -3.122544936980531
            1.1646013060987537
            -1.045883736913656
            -0.7360385805561237
            -1.8286115164963372
            0.5617416714149454
            3.4073456854331456
            -4.165240744439656
    Node 10:
        Bias:
            1.2963275963331196
        Incoming weights:
            0.8754219366993842
            0.3400527668719386
            -3.868514448269394
            -0.4236470589897488
            -0.6746868220765949
            -1.0940406597751946
            -0.12306074525104002
            -3.9176478489037603
            2.7734108594955185
            -2.0926596491779796

Layer 5:
    Node 1:
        Bias:
            12.202559992853493
        Incoming weights:
            -19.677871660644236
            8.433138849515442
            3.459596532617246
            -0.40024907777716434
            1.425334573420559
            0.33354455466927047
            1.9434921513779035
            1.0871322944870139
            2.834373921215209
            4.628457550883744

